{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What makes mloda unique?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, data systems may appear straightforward: input data goes in and output data goes out.\n",
    "\n",
    "The inherent complexity, however, lies in the details:\n",
    "\n",
    "- ensuring data reusability\n",
    "- supporting a wide range of technologies across software and ML lifecycles\n",
    "- addressing the needs of different user groups\n",
    "\n",
    "mloda redefines traditional data management by shifting focus from the data itself to the dynamic processes surrounding it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data should be reuseable\n",
    "\n",
    "In most organizations, data pipelines are often built with a single-purpose focus. This tight coupling of data and data transformation within the same process limits reusability. For example:\n",
    "\n",
    "```SQL\n",
    "select lower(data) from table into other_table;\n",
    "```\n",
    "\n",
    "In this scenario, embedding data specifics into the process prevents sharing or adapting it for other tasks, leading to repeated rewrites and wasted effort.\n",
    "\n",
    "mloda addresses this issue by decoupling data and process definitions - the features. Instead of combining them in a single process, data and the features are treated as separate entities that come together only during calculation time. The following code snippet of mloda brings together data and features:\n",
    "\n",
    "```python\n",
    "def calculate_feature(cls, data: Any, features: FeatureSet) -> Any:\n",
    "    ...\n",
    "```\n",
    "\n",
    "In this model:\n",
    "\n",
    "- Data remains independent and can be sourced from various locations\n",
    "- Features represent the process definitions (transformations) applied to the data\n",
    "\n",
    "Benefits of Decoupling Data and Features:\n",
    "\n",
    "- Process Flexibility: Switching between different processing modes is made simple and intuitive, such as batch and stream processing could be done using the same features\n",
    "- Artifact and Validation Reusability: Input and output feature artifacts, along with their validations, can be repurposed across projects or teams\n",
    "- Production-Ready Functionality: Centralized features such as global logging, monitoring of data usage, and lineage tracking can be consistently applied across all pipelines\n",
    "\n",
    "This modular approach not only reduces redundancy but also creates a robust framework for scaling data transformations efficiently across diverse use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accommodating different technologies across software and ML lifecycles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In current systems, data processes are tightly coupled with the technologies used at specific lifecycle stagesâ€”ETL systems for batch pipelines, streaming platforms for real-time applications, and ML frameworks for training. This rigid coupling makes it challenging to adapt to changing technologies or switch between processing modes.\n",
    "\n",
    "Metadata management further complicates the situation, it is kept fragmented across separate tools:\n",
    "\n",
    "| **Tool/Feature**                | **Purpose**                              |\n",
    "|----------------------------------|------------------------------------------|\n",
    "| **Feature Stores**               | Managing ML features                     |\n",
    "| **Data Catalogs**                | Organizing base data                     |\n",
    "| **Pipeline Orchestration Tools** | Managing workflows                       |\n",
    "| **Monitoring Systems**           | Tracking data quality and performance    |\n",
    "\n",
    "This siloed approach leads to redundancy, inefficiencies, and considerable complexity when maintaining metadata and integrating tools.\n",
    "mloda tackles these issues by decoupling data and processes, where processes are inherently reusable and adaptable, thereby reducing redundancy and ensuring lifecycle consistency.\n",
    "\n",
    "As shown in the previous notebook, each Feature can be calculated using its own technology!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing the Needs of Diverse User Groups with mloda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditional data systems are fragmented and often inefficient. mloda tackles these challenges for data producers, users, and owners:\n",
    "\n",
    "| User            | Problem                          | mloda Framework                               |\n",
    "|------------------|----------------------------------|-----------------------------------------------|\n",
    "| **Data Producers** | Limited freedom in tools      | Decouples processes, allowing tool flexibility. |\n",
    "|                  | Cumbersome APIs                 | Simplifies with standardized, user-friendly APIs. |\n",
    "|                  | Knowledge gaps for meta data    | Adds metadata tracking through whole lifecycle  |\n",
    "| **Data Users**   | Fragmented access               | Unified API simplifies navigation.             |\n",
    "|                  | Reusability gaps                | Central repository enables easy reuse.        |\n",
    "|                  | Customization constraints       | Offers configurable workflows and templates.  |\n",
    "| **Data Owners**  | Siloed governance               | Centralizes governance for consistency.       |\n",
    "|                  | Ambiguous accountability        | Tracks ownership for transparency.            |\n",
    "|                  | Compliance risks                | Standardizes processes for compliance.        |\n",
    "\n",
    "\n",
    "mloda is designed to prioritize seamless interfaces between these roles, unifying workflows and aiming at simplified collaboration. Our current development efforts are focused on enhancing the experiences for data producers and data users, with improvements for data owners actively underway."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
